{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, coo_matrix, lil_matrix, dok_matrix\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from networkx.generators.community import planted_partition_graph\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0 4.47213595499958 1.118033988749895\n"
     ]
    }
   ],
   "source": [
    "N = 1 * 10**5\n",
    "q = 2\n",
    "\n",
    "average_degree = 5.0 # average degree\n",
    "diff = 7.5 # cin - cout\n",
    "cout = average_degree * 2 - diff\n",
    "cin = average_degree * 2 - cout\n",
    "seed = 13\n",
    "print(cin-cout, 2*np.sqrt(average_degree), (cin-cout)/(2*np.sqrt(average_degree)))\n",
    "\n",
    "G = planted_partition_graph(q, int(N/q), cin / N, cout / N, seed=seed)\n",
    "partition = np.zeros(N)\n",
    "for i, part in enumerate(G.graph['partition']):\n",
    "    partition[list(part)] = i\n",
    "    \n",
    "A = nx.adjacency_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_graph(G, subset = None):\n",
    "    if not subset:\n",
    "        subset = {}\n",
    "        \n",
    "    figure(figsize=(10, 10/1.33))\n",
    "    node_types = [1 if node in subset else 0 for node in G.nodes()]\n",
    "    rng = np.random.RandomState(1)\n",
    "    pos = {node: rng.rand(2) for node in G.nodes()}\n",
    "    nx.draw_networkx(\n",
    "        G, \n",
    "        node_color=node_types, \n",
    "        with_labels=False, \n",
    "        pos=nx.spring_layout(G, pos = pos, k=7.00/np.sqrt(len(G)))\n",
    "    )\n",
    "    \n",
    "#plot_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50, 1.00\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "L = nx.normalized_laplacian_matrix(G)\n",
    "vals, vecs = scipy.sparse.linalg.eigsh(L, which=\"SA\", k=3)\n",
    "kmeans.fit(vecs[:,1:])\n",
    "labels = kmeans.labels_\n",
    "#labels = (vecs[:,0] <= 0).astype(np.int)\n",
    "size_of_partition = np.sum(labels == 0) / vecs.shape[0]\n",
    "partitioning = max(size_of_partition, 1-size_of_partition)\n",
    "accuracy = (partition == labels).mean()\n",
    "print(f\"{max(accuracy, 1-accuracy):.2f}, {partitioning:.2f}\")\n",
    "\n",
    "#subset = set(np.argwhere(labels).flatten().tolist())\n",
    "#plot_graph(G, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unweighted_bethe_hessian(adjacency_matrix):\n",
    "    n = adjacency_matrix.shape[0]\n",
    "    diags = np.asarray(adjacency_matrix.sum(axis=1).flatten())\n",
    "    D = scipy.sparse.spdiags(diags, [0], n, n, format='csr')\n",
    "    I = scipy.sparse.eye(n, format='csr')\n",
    "    r = np.sqrt(np.mean(diags**2) / np.mean(diags) - 1)\n",
    "    Hr = (r ** 2 - 1) * I - r * adjacency_matrix + D\n",
    "    return Hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bethe_hessian = build_unweighted_bethe_hessian(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, vecs = eigsh(bethe_hessian, 2, which='SA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (partition == (vecs[:,1] <= 0).astype(np.int)).mean()\n",
    "max(accuracy, 1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7025"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(vecs[:,1:])\n",
    "accuracy = (partition == kmeans.labels_).mean()\n",
    "max(accuracy, 1-accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset = set(np.argwhere(vecs[:,1] <= 0).flatten().tolist())\n",
    "#plot_graph(G, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def build_pmi_matrix(adjacency_matrix, neg):\n",
    "    n = adjacency_matrix.shape[0]\n",
    "    diags = np.asarray(adjacency_matrix.sum(axis=1)).flatten()\n",
    "    with scipy.errstate(divide='ignore'):\n",
    "        diags_inv = 1.0 / diags\n",
    "    diags_inv[scipy.isinf(diags_inv)] = 0\n",
    "    D_inv = scipy.sparse.spdiags(diags_inv, [0], n, n, format='csr')\n",
    "    pmi = D_inv.dot(adjacency_matrix.dot(D_inv))\n",
    "    #dataset_size = adjacency_matrix.sum()\n",
    "    #print(adjacency_matrix.sum())\n",
    "    dataset_size = 1.0\n",
    "    pmi.data = np.log(pmi.data * dataset_size / neg)\n",
    "    \n",
    "    with scipy.errstate(divide='ignore'):\n",
    "        diags_inv = np.log((1.0 / diags)*dataset_size / neg)\n",
    "    diags_inv[scipy.isinf(diags_inv)] = 0\n",
    "    D_inv = scipy.sparse.spdiags(diags_inv, [0], n, n, format='csr')\n",
    "    \n",
    "    #pmi.data[pmi.data < 0] = 0\n",
    "    return pmi\n",
    "\n",
    "def build_tfidf_matrix(adjacency_matrix, neg):\n",
    "    n = adjacency_matrix.shape[0]\n",
    "    diags = np.asarray(adjacency_matrix.sum(axis=1)).flatten()\n",
    "    total_sum = adjacency_matrix.sum()\n",
    "    with scipy.errstate(divide='ignore'):\n",
    "        diags_inv = np.log(total_sum / diags)\n",
    "    diags_inv[scipy.isinf(diags_inv)] = 0\n",
    "    D_inv = scipy.sparse.spdiags(diags_inv, [0], n, n, format='csr')\n",
    "    tfidf = adjacency_matrix.dot(D_inv)\n",
    "    return tfidf\n",
    "\n",
    "def pmi_laplacian(pmi):\n",
    "    n = pmi.shape[0]\n",
    "    diags = np.asarray(pmi.sum(axis=1).flatten())\n",
    "    D = scipy.sparse.spdiags(diags, [0], n, n, format='csr')\n",
    "    return D - pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3, 1.10, 0.500, 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse.linalg import eigsh, svds\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "\n",
    "#for k in range(10, 100, 10):\n",
    "k=3\n",
    "tfidf = build_tfidf_matrix(A.astype(np.float64), 1)\n",
    "#pmi = build_pmi_matrix(A.astype(np.float64), k / 25000)\n",
    "#pmi = build_pmi_matrix(A.astype(np.float64), 1)\n",
    "#pmi = pmi_laplacian(pmi)\n",
    "vecs, vals, vecs2 = svds(tfidf, 3, which='LM')\n",
    "# vals, vecs = eigsh(pmi, 3, which='LM')\n",
    "#print(vals)\n",
    "kmeans.fit(vecs)\n",
    "labels = kmeans.labels_\n",
    "#labels = (vecs[:,0] <= 0).astype(np.int)\n",
    "size_of_partition = np.sum(labels == 0) / vecs.shape[0]\n",
    "partitioning = max(size_of_partition, 1-size_of_partition)\n",
    "accuracy = (partition == labels).mean()\n",
    "print(f\"{k}, {np.log(k):.2f}, {max(accuracy, 1-accuracy):.3f}, {partitioning:.2f}\")\n",
    "\n",
    "#subset = set(np.argwhere(labels).flatten().tolist())\n",
    "#plot_graph(G, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.232091614508498"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-18.46160273,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [  0.        , -17.95077711,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [  0.        ,   0.        , -17.95077711,   0.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        , -17.76845555,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         -17.76845555,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        , -18.46160273,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        , -17.48077348,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ,   0.        , -18.46160273,\n",
       "           0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         -18.46160273,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        , -18.17392066]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi[:10,:10].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pmi = build_pmi_matrix(A.astype(np.float64), 1.0)\n",
    "pmi.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.437751649736401"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi.data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
